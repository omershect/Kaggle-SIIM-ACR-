{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {
          "5b66213a18de4501a895fed1ccbb9b5b": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "IntProgressModel",
            "state": {
              "_dom_classes": [],
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "1.5.0",
              "_model_name": "IntProgressModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/controls",
              "_view_module_version": "1.5.0",
              "_view_name": "ProgressView",
              "bar_style": "",
              "description": "",
              "description_tooltip": null,
              "layout": "IPY_MODEL_8ef0ef7a328144f6baf584a7d882f859",
              "max": 3205,
              "min": 0,
              "orientation": "horizontal",
              "style": "IPY_MODEL_b7a69e7e98c546e5b9ac2f723b5f322a",
              "value": 3205
            }
          },
          "614462bfb4974be8b7e82fdf22836acb": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "HBoxModel",
            "state": {
              "_dom_classes": [],
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "1.5.0",
              "_model_name": "HBoxModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/controls",
              "_view_module_version": "1.5.0",
              "_view_name": "HBoxView",
              "box_style": "",
              "children": [
                "IPY_MODEL_5b66213a18de4501a895fed1ccbb9b5b",
                "IPY_MODEL_9ca351f5f1f8474ab944a3663af72395"
              ],
              "layout": "IPY_MODEL_f7cf875c80db45af986cd0c1c6332db1"
            }
          },
          "859e9738536446c2a3c3ab43a3cb06a1": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "DescriptionStyleModel",
            "state": {
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "1.5.0",
              "_model_name": "DescriptionStyleModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "1.2.0",
              "_view_name": "StyleView",
              "description_width": ""
            }
          },
          "8ef0ef7a328144f6baf584a7d882f859": {
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "1.2.0",
            "model_name": "LayoutModel",
            "state": {
              "_model_module": "@jupyter-widgets/base",
              "_model_module_version": "1.2.0",
              "_model_name": "LayoutModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "1.2.0",
              "_view_name": "LayoutView",
              "align_content": null,
              "align_items": null,
              "align_self": null,
              "border": null,
              "bottom": null,
              "display": null,
              "flex": null,
              "flex_flow": null,
              "grid_area": null,
              "grid_auto_columns": null,
              "grid_auto_flow": null,
              "grid_auto_rows": null,
              "grid_column": null,
              "grid_gap": null,
              "grid_row": null,
              "grid_template_areas": null,
              "grid_template_columns": null,
              "grid_template_rows": null,
              "height": null,
              "justify_content": null,
              "justify_items": null,
              "left": null,
              "margin": null,
              "max_height": null,
              "max_width": null,
              "min_height": null,
              "min_width": null,
              "object_fit": null,
              "object_position": null,
              "order": null,
              "overflow": null,
              "overflow_x": null,
              "overflow_y": null,
              "padding": null,
              "right": null,
              "top": null,
              "visibility": null,
              "width": null
            }
          },
          "9aea2e902de14ce5937b3d3bece9a89b": {
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "1.2.0",
            "model_name": "LayoutModel",
            "state": {
              "_model_module": "@jupyter-widgets/base",
              "_model_module_version": "1.2.0",
              "_model_name": "LayoutModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "1.2.0",
              "_view_name": "LayoutView",
              "align_content": null,
              "align_items": null,
              "align_self": null,
              "border": null,
              "bottom": null,
              "display": null,
              "flex": null,
              "flex_flow": null,
              "grid_area": null,
              "grid_auto_columns": null,
              "grid_auto_flow": null,
              "grid_auto_rows": null,
              "grid_column": null,
              "grid_gap": null,
              "grid_row": null,
              "grid_template_areas": null,
              "grid_template_columns": null,
              "grid_template_rows": null,
              "height": null,
              "justify_content": null,
              "justify_items": null,
              "left": null,
              "margin": null,
              "max_height": null,
              "max_width": null,
              "min_height": null,
              "min_width": null,
              "object_fit": null,
              "object_position": null,
              "order": null,
              "overflow": null,
              "overflow_x": null,
              "overflow_y": null,
              "padding": null,
              "right": null,
              "top": null,
              "visibility": null,
              "width": null
            }
          },
          "9ca351f5f1f8474ab944a3663af72395": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "HTMLModel",
            "state": {
              "_dom_classes": [],
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "1.5.0",
              "_model_name": "HTMLModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/controls",
              "_view_module_version": "1.5.0",
              "_view_name": "HTMLView",
              "description": "",
              "description_tooltip": null,
              "layout": "IPY_MODEL_9aea2e902de14ce5937b3d3bece9a89b",
              "placeholder": "​",
              "style": "IPY_MODEL_859e9738536446c2a3c3ab43a3cb06a1",
              "value": "100% 3204/3205 [12:38&lt;00:00,  4.39it/s]"
            }
          },
          "b7a69e7e98c546e5b9ac2f723b5f322a": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "ProgressStyleModel",
            "state": {
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "1.5.0",
              "_model_name": "ProgressStyleModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "1.2.0",
              "_view_name": "StyleView",
              "bar_color": null,
              "description_width": ""
            }
          },
          "f7cf875c80db45af986cd0c1c6332db1": {
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "1.2.0",
            "model_name": "LayoutModel",
            "state": {
              "_model_module": "@jupyter-widgets/base",
              "_model_module_version": "1.2.0",
              "_model_name": "LayoutModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "1.2.0",
              "_view_name": "LayoutView",
              "align_content": null,
              "align_items": null,
              "align_self": null,
              "border": null,
              "bottom": null,
              "display": null,
              "flex": null,
              "flex_flow": null,
              "grid_area": null,
              "grid_auto_columns": null,
              "grid_auto_flow": null,
              "grid_auto_rows": null,
              "grid_column": null,
              "grid_gap": null,
              "grid_row": null,
              "grid_template_areas": null,
              "grid_template_columns": null,
              "grid_template_rows": null,
              "height": null,
              "justify_content": null,
              "justify_items": null,
              "left": null,
              "margin": null,
              "max_height": null,
              "max_width": null,
              "min_height": null,
              "min_width": null,
              "object_fit": null,
              "object_position": null,
              "order": null,
              "overflow": null,
              "overflow_x": null,
              "overflow_y": null,
              "padding": null,
              "right": null,
              "top": null,
              "visibility": null,
              "width": null
            }
          }
        },
        "version_major": 2,
        "version_minor": 0
      }
    },
    "colab": {
      "name": "Inference_stage_2_unet_resnet34.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtiBpZYgSRPo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "SIIM-ACR Pneumothorax Segmentation \n",
        "\n",
        "Infernce kernel for Unet Resnet 34 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2RBICkoSo8h",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "BV9bWofLSRPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import pdb\n",
        "import time\n",
        "import warnings\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import DataLoader, Dataset, sampler\n",
        "from matplotlib import pyplot as plt\n",
        "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
        "from albumentations.torch import ToTensor\n",
        "from torchvision import transforms\n",
        "\n",
        " \n",
        "from matplotlib.pyplot import figure\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHrpJ2erS17J",
        "colab_type": "text"
      },
      "source": [
        "## Segmentation Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3DgzePmSRPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install git+https://github.com/qubvel/segmentation_models.pytorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYjOZdnQSRP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import segmentation_models_pytorch as smp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBcfC1rmSRP2",
        "colab_type": "text"
      },
      "source": [
        "## Global Variables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNzmAPp0SRP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE =1024\n",
        "BATCH_SIZE = 2\n",
        "EPOCH = 65"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRY_aGgcSRP5",
        "colab_type": "text"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfz53zdrSRP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_length_decode(rle, height=1024, width=1024, fill_value=1):\n",
        "    component = np.zeros((height, width), np.float32)\n",
        "    component = component.reshape(-1)\n",
        "    rle = np.array([int(s) for s in rle.strip().split(' ')])\n",
        "    rle = rle.reshape(-1, 2)\n",
        "    start = 0\n",
        "    for index, length in rle:\n",
        "        start = start+index\n",
        "        end = start+length\n",
        "        component[start: end] = fill_value\n",
        "        start = end\n",
        "    component = component.reshape(width, height).T\n",
        "    return component\n",
        "\n",
        "def run_length_encode(component):\n",
        "    component = component.T.flatten()\n",
        "    start = np.where(component[1:] > component[:-1])[0]+1\n",
        "    end = np.where(component[:-1] > component[1:])[0]+1\n",
        "    length = end-start\n",
        "    rle = []\n",
        "    for i in range(len(length)):\n",
        "        if i == 0:\n",
        "            rle.extend([start[0], length[0]])\n",
        "        else:\n",
        "            rle.extend([start[i]-end[i-1], length[i]])\n",
        "    rle = ' '.join([str(r) for r in rle])\n",
        "    return rle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYI9DRI1SRP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission_path = '../input/siim-acr-pneumothorax-segmentation/stage_2_sample_submission.csv'\n",
        "train_rle_path = '../input/siim-dicom-images/train-rle.csv'\n",
        "data_folder = \"../input/siim-png-images/input/train_png\"\n",
        "#test_data_folder = \"../input/siim-png-images/input/test_png\"\n",
        "test_data_folder = \"../input/stage2-test-images/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgdQ2QeoSRP_",
        "colab_type": "text"
      },
      "source": [
        "## Some more utility functions\n",
        "\n",
        "Here are some utility functions for calculating IoU and Dice scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AluMR1KeSRP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, threshold):\n",
        "    X_p = np.copy(X)\n",
        "    preds = (X_p > threshold).astype('uint8')\n",
        "    return preds\n",
        "\n",
        "def metric(probability, truth, threshold=0.5, reduction='none'):\n",
        "    '''Calculates dice of positive and negative images seperately'''\n",
        "    '''probability and truth must be torch tensors'''\n",
        "    batch_size = len(truth)\n",
        "    with torch.no_grad():\n",
        "        probability = probability.view(batch_size, -1)\n",
        "        truth = truth.view(batch_size, -1)\n",
        "        assert(probability.shape == truth.shape)\n",
        "\n",
        "        p = (probability > threshold).float()\n",
        "        t = (truth > 0.5).float()\n",
        "\n",
        "        t_sum = t.sum(-1)\n",
        "        p_sum = p.sum(-1)\n",
        "        neg_index = torch.nonzero(t_sum == 0)\n",
        "        pos_index = torch.nonzero(t_sum >= 1)\n",
        "\n",
        "        dice_neg = (p_sum == 0).float()\n",
        "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n",
        "\n",
        "        dice_neg = dice_neg[neg_index]\n",
        "        dice_pos = dice_pos[pos_index]\n",
        "        dice = torch.cat([dice_pos, dice_neg])\n",
        "\n",
        "        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n",
        "        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n",
        "        dice = dice.mean().item()\n",
        "\n",
        "        num_neg = len(neg_index)\n",
        "        num_pos = len(pos_index)\n",
        "\n",
        "    return dice, dice_neg, dice_pos, num_neg, num_pos\n",
        "\n",
        "class Meter:\n",
        "    '''A meter to keep track of iou and dice scores throughout an epoch'''\n",
        "    def __init__(self, phase, epoch):\n",
        "        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n",
        "        self.base_dice_scores = []\n",
        "        self.dice_neg_scores = []\n",
        "        self.dice_pos_scores = []\n",
        "        self.iou_scores = []\n",
        "\n",
        "    def update(self, targets, outputs):\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        dice, dice_neg, dice_pos, _, _ = metric(probs, targets, self.base_threshold)\n",
        "        self.base_dice_scores.append(dice)\n",
        "        self.dice_pos_scores.append(dice_pos)\n",
        "        self.dice_neg_scores.append(dice_neg)\n",
        "        preds = predict(probs, self.base_threshold)\n",
        "        iou = compute_iou_batch(preds, targets, classes=[1])\n",
        "        self.iou_scores.append(iou)\n",
        "\n",
        "    def get_metrics(self):\n",
        "        dice = np.mean(self.base_dice_scores)\n",
        "        dice_neg = np.mean(self.dice_neg_scores)\n",
        "        dice_pos = np.mean(self.dice_pos_scores)\n",
        "        dices = [dice, dice_neg, dice_pos]\n",
        "        iou = np.mean(self.iou_scores)\n",
        "        return dices, iou\n",
        "\n",
        "def epoch_log(phase, epoch, epoch_loss, meter, start):\n",
        "    '''logging the metrics at the end of an epoch'''\n",
        "    dices, iou = meter.get_metrics()\n",
        "    dice, dice_neg, dice_pos = dices\n",
        "    print(\"dice: %0.4f | dice_neg: %0.4f | dice_pos: %0.4f | IoU: %0.4f\" % (dice, dice_neg, dice_pos, iou))\n",
        "    return None\n",
        "\n",
        "def compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n",
        "    '''computes iou for one ground truth mask and predicted mask'''\n",
        "    pred[label == ignore_index] = 0\n",
        "    ious = []\n",
        "    for c in classes:\n",
        "        label_c = label == c\n",
        "        if only_present and np.sum(label_c) == 0:\n",
        "            ious.append(np.nan)\n",
        "            continue\n",
        "        pred_c = pred == c\n",
        "        intersection = np.logical_and(pred_c, label_c).sum()\n",
        "        union = np.logical_or(pred_c, label_c).sum()\n",
        "        if union != 0:\n",
        "            ious.append(intersection / union)\n",
        "    return ious if ious else [1]\n",
        "\n",
        "\n",
        "def compute_iou_batch(outputs, labels, classes=None):\n",
        "    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n",
        "    ious = []\n",
        "    preds = np.copy(outputs) # copy is imp\n",
        "    labels = np.array(labels) # tensor to np\n",
        "    for pred, label in zip(preds, labels):\n",
        "        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n",
        "    iou = np.nanmean(ious)\n",
        "    return iou\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-yp0rUYSRQC",
        "colab_type": "text"
      },
      "source": [
        "## UNet with ResNet34 \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlJFTB5wSRQC",
        "colab_type": "code",
        "outputId": "e99bf3ad-4aad-4361-82c2-f8c4eb9a0671",
        "colab": {}
      },
      "source": [
        "model1 = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", activation=None)\n",
        "model2 = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", activation=None)\n",
        "model3 = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", activation=None)\n",
        "model4 = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", activation=None)\n",
        "model5 = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", activation=None)\n",
        "model6 = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", activation=None)\n",
        " \n",
        " \n",
        "\n",
        "model1.cuda()\n",
        "model2.cuda()\n",
        "model3.cuda()\n",
        "model4.cuda()\n",
        "model5.cuda()\n",
        "model6.cuda()\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /tmp/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 112MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unet(\n",
              "  (encoder): ResNetEncoder(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (5): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (decoder): UnetDecoder(\n",
              "    (layer1): DecoderBlock(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dReLU(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Conv2dReLU(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer2): DecoderBlock(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dReLU(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Conv2dReLU(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer3): DecoderBlock(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dReLU(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Conv2dReLU(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer4): DecoderBlock(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dReLU(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Conv2dReLU(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layer5): DecoderBlock(\n",
              "      (block): Sequential(\n",
              "        (0): Conv2dReLU(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Conv2dReLU(\n",
              "          (block): Sequential(\n",
              "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqEJKB5JSRQF",
        "colab_type": "text"
      },
      "source": [
        "## Test prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYt_IBIoSRQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, root, df, size, mean, std, tta=4):\n",
        "        self.root = root\n",
        "        self.size = size\n",
        "       \n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.fnames = list(df[\"ImageId\"])\n",
        "        self.num_samples = len(self.fnames)\n",
        "        self.transforms = get_transforms(size, mean, std)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.fnames[idx]\n",
        "        path = os.path.join(self.root, fname + \".png\")\n",
        "        image = cv2.imread(path)\n",
        "        augmented = self.transforms(image=image)\n",
        "        image = augmented['image']\n",
        "       \n",
        "        return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "    \n",
        "    \n",
        "    \n",
        "def get_transforms(size, mean, std):\n",
        "        list_transforms = []\n",
        "        \n",
        "        list_transforms.extend(\n",
        "        [\n",
        "            Normalize(mean=mean, std=std, p=1),\n",
        "            Resize(size, size),\n",
        "            ToTensor(),\n",
        "        ]\n",
        "    )\n",
        "        \n",
        "        list_trfms = Compose(list_transforms)\n",
        "        return list_trfms\n",
        "\n",
        "def post_process(probability, threshold, min_size):\n",
        "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
        "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
        "    predictions = np.zeros((1024, 1024), np.float32)\n",
        "    num = 0\n",
        "    for c in range(1, num_component):\n",
        "        p = (component == c)\n",
        "        if p.sum() > min_size:\n",
        "            predictions[p] = 1\n",
        "            num += 1\n",
        "    return predictions, num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YvuYBIzSRQH",
        "colab_type": "code",
        "outputId": "9ff71b3b-ab3c-49da-b121-52fdf30c95bc",
        "colab": {}
      },
      "source": [
        "size = IMAGE_SIZE\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "num_workers = 8\n",
        "batch_size = 1\n",
        "best_threshold = 0.5\n",
        "min_size = 3500\n",
        "device = torch.device(\"cuda:0\")\n",
        "df = pd.read_csv(sample_submission_path)\n",
        "testset = DataLoader(\n",
        "    TestDataset(test_data_folder, df, size, mean, std),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "#model = model_trainer.net # get the model from model_trainer object\n",
        "\n",
        "\n",
        "\n",
        "model1.eval()\n",
        "state = torch.load('../input/unetresnet34-run3-04-09/UnetResnet34_Run3__04_09.pth', map_location=lambda storage, loc: storage)\n",
        "model1.load_state_dict(state[\"state_dict\"])\n",
        "\n",
        "\n",
        "model2.eval()\n",
        "state = torch.load('../input/unet-resnet34-01-09/Unet_resnet34_run2_01_09.pth', map_location=lambda storage, loc: storage)\n",
        "model2.load_state_dict(state[\"state_dict\"])\n",
        "\n",
        "\n",
        "\n",
        "model3.eval()\n",
        "state = torch.load('../input/unetresnet34-stage2-run3-02-09/UnetTesnet34_Run3_Stage2_02_09.pth', map_location=lambda storage, loc: storage)\n",
        "model3.load_state_dict(state[\"state_dict\"])\n",
        "\n",
        "\n",
        "model4.eval()\n",
        "state = torch.load('../input/unetresn34-run3-02-09-v2/Unetresnet34_run3_V2.pth', map_location=lambda storage, loc: storage)\n",
        "model4.load_state_dict(state[\"state_dict\"])\n",
        "\n",
        "\n",
        "model5.eval()\n",
        "state = torch.load('../input/unet-resnet34-stage2-run2-31-08/Unet_Resnet34_Run2_Stage2_31_08.pth', map_location=lambda storage, loc: storage)\n",
        "model5.load_state_dict(state[\"state_dict\"])\n",
        "\n",
        "\n",
        "model6.eval()\n",
        "state = torch.load('../input/unetresnet34-run3-05-09/model.pth', map_location=lambda storage, loc: storage)\n",
        "model6.load_state_dict(state[\"state_dict\"])\n",
        "\n",
        "\n",
        "for param in model1.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "for param in model2.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model3.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model4.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "for param in model5.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "for param in model6.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "encoded_pixels = []\n",
        "#dataloader_iterator = iter(testset2)\n",
        "for i, batch in enumerate(tqdm(testset)):\n",
        "   \n",
        "   \n",
        "    preds = torch.sigmoid(model1(batch.to(device)))\n",
        "    preds = preds.detach().cpu().numpy()[:, 0, :, :] # (batch_size, 1, size, size) -> (batch_size, size, size)\n",
        "    \n",
        "   \n",
        "    preds2 = torch.sigmoid(model2(batch.to(device)))\n",
        "    preds2 = preds2.detach().cpu().numpy()[:, 0, :, :] # (batch_size, 1, size, size) -> (batch_size, size, size)\n",
        "    \n",
        "    preds3 = torch.sigmoid(model3(batch.to(device)))\n",
        "    preds3 = preds3.detach().cpu().numpy()[:, 0, :, :] # (batch_size, 1, size, size) -> (batch_size, size, size)\n",
        "   \n",
        "    preds4 = torch.sigmoid(model4(batch.to(device)))\n",
        "    preds4 = preds4.detach().cpu().numpy()[:, 0, :, :] # (batch_size, 1, size, size) -> (batch_size, size, size)\n",
        "    \n",
        "    preds5 = torch.sigmoid(model5(batch.to(device)))\n",
        "    preds5 = preds5.detach().cpu().numpy()[:, 0, :, :] # (batch_size, 1, size, size) -> (batch_size, size, size)\n",
        "   \n",
        "    preds6 = torch.sigmoid(model6(batch.to(device)))\n",
        "    preds6 = preds6.detach().cpu().numpy()[:, 0, :, :] # (batch_size, 1, size, size) -> (batch_size, size, size)\n",
        "   \n",
        "    \n",
        "    preds = ( preds+ preds2 + preds3 + preds4 +  preds6) / 5.0 \n",
        "  \n",
        "    for probability in preds:\n",
        "        if probability.shape != (1024, 1024):\n",
        "            probability = cv2.resize(probability, dsize=(1024, 1024), interpolation=cv2.INTER_LINEAR)\n",
        "        predict, num_predict = post_process(probability, best_threshold, min_size)\n",
        "        if num_predict == 0:\n",
        "            encoded_pixels.append('-1')\n",
        "        else:\n",
        "            r = run_length_encode(predict)\n",
        "            encoded_pixels.append(r)\n",
        "df['EncodedPixels'] = encoded_pixels\n",
        "df.to_csv('submission.csv', columns=['ImageId', 'EncodedPixels'], index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "614462bfb4974be8b7e82fdf22836acb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=3205), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}